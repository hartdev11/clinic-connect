/**
 * Chat Orchestrator ‚Äî 7-Agent Flow (Enterprise)
 * 0. Pre-LLM Safety ‚Äî classify, block/escalate ‡∏Å‡πà‡∏≠‡∏ô LLM
 * 1. Customer Memory ‚Äî ‡πÇ‡∏´‡∏•‡∏î long-term memory
 * 2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å 6 Analytics Agents ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏ô
 * 3. Cross-Agent Reasoning
 * 4. Role Manager (1 LLM call) ‚Äî ‡πÉ‡∏ä‡πâ prompt registry, cost governance
 * 5. AI Observability ‚Äî log activity
 */
import { runAllAnalytics } from "./run-analytics";
import { runRoleManager } from "./role-manager";
import { runCrossAgentReasoning } from "./cross-agent-reasoning";
import { classifyPreLLM, SAFETY_FALLBACK_MESSAGES } from "./pre-llm-safety";
import { getCustomerMemory, upsertCustomerMemory, shouldSummarize } from "./customer-memory-store";
import { checkBudgetHardStop } from "./cost-governance";
import { logAIActivity, checkPolicyViolation } from "./ai-observability";
import { runMemorySummarizationForCustomer } from "./memory-summarization";
import {
  getCachedResponse,
  setCachedResponse,
  computeReplyConfidence,
  checkHallucination,
  tagFailure,
} from "./ai-feedback-loop";
import {
  classifyRetrievalComplexity,
  shouldSkipVectorSearch,
  getDeterministicCachedReply,
} from "./cost-aware-retrieval";
import { FAILSAFE_MESSAGE, isFailsafeError } from "@/lib/knowledge-brain/failsafe";
import { acquireLLMSlot } from "./ai-queue";
import { processBookingIntent } from "./booking-intent";
import type { AnalyticsContext } from "./types";

export interface ChatOrchestratorInput {
  message: string;
  org_id: string;
  branch_id?: string | null;
  userId?: string | null;
  correlationId?: string;
  /** Enterprise: ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠ (line, web) ‚Äî ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI booking */
  channel?: "line" | "web" | null;
}

export interface ChatOrchestratorOutput {
  reply: string;
  success: boolean;
  analyticsMs?: number;
  roleManagerMs?: number;
  totalMs?: number;
  error?: string;
  usage?: { prompt_tokens: number; completion_tokens: number; total_tokens: number };
  /** Phase 2 #20: For feedback loop trace */
  correlationId?: string;
  /** When promotion/media exists ‚Äî channel adapters send images/videos */
  media?: string[];
}

/**
 * ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å 7-Agent pipeline
 * ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
 */
export async function chatOrchestrate(
  input: ChatOrchestratorInput
): Promise<ChatOrchestratorOutput> {
  const start = Date.now();

  const correlationId = input.correlationId ?? `chat_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`;
  const trimmed = input.message?.trim();
  if (!trimmed || trimmed.length < 2) {
    return {
      reply: "‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞ ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏π‡πÉ‡∏´‡πâ",
      success: true,
      totalMs: Date.now() - start,
      correlationId,
    };
  }

  // Pre-LLM Safety ‚Äî block/escalate ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
  const safety = classifyPreLLM(trimmed);
  if (safety.block || (safety.escalate && safety.classification !== "safe")) {
    const fallback = SAFETY_FALLBACK_MESSAGES[safety.classification];
    if (fallback) {
      return {
        reply: fallback,
        success: true,
        totalMs: Date.now() - start,
      };
    }
  }

  // Cost Governance ‚Äî hard stop ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô budget
  const budgetCheck = await checkBudgetHardStop(input.org_id);
  if (!budgetCheck.allowed) {
    return {
      reply: "‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ï‡πá‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏∞ ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞",
      success: false,
      totalMs: Date.now() - start,
      error: budgetCheck.reason,
    };
  }

  // Phase 3 #7: Cost-aware ‚Äî low complexity or cached FAQ
  const complexity = classifyRetrievalComplexity(trimmed);
  const cachedReply = await getDeterministicCachedReply(input.org_id, trimmed);
  if (cachedReply) {
    return { reply: cachedReply, success: true, totalMs: Date.now() - start, correlationId };
  }
  if (shouldSkipVectorSearch(complexity)) {
    return {
      reply: "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞",
      success: true,
      totalMs: Date.now() - start,
      correlationId,
    };
  }

  const cached = await getCachedResponse({ org_id: input.org_id, userMessage: trimmed });
  if (cached) {
    return { reply: cached, success: true, totalMs: Date.now() - start, correlationId };
  }

  // Enterprise: AI Booking Assistant ‚Äî ‡∏à‡∏≠‡∏á/‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô/‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å
  const hasBookingKeyword = /‡∏à‡∏≠‡∏á|booking|‡∏ô‡∏±‡∏î|‡∏™‡∏°‡∏±‡∏Ñ‡∏£|‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏î/i.test(trimmed);
  const hasPhoneAndProcedure =
    /\b0\d{8,9}\b/.test(trimmed.replace(/\s/g, "")) &&
    /‡πÇ‡∏ö‡∏ó‡πá‡∏≠‡∏Å‡∏ã‡πå|‡∏ü‡∏¥‡∏•‡πÄ‡∏•‡∏≠‡∏£‡πå|‡πÄ‡∏•‡πÄ‡∏ã‡∏≠‡∏£‡πå|‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà|‡πÄ‡∏ß‡∏•‡∏≤|\d+‡πÇ‡∏°‡∏á/i.test(trimmed);
  const isBookingIntent = hasBookingKeyword || hasPhoneAndProcedure;
  const bookingResult = await processBookingIntent(trimmed, input.org_id, {
    branchId: input.branch_id,
    channel: input.channel === "line" ? "line" : input.channel === "web" ? "web" : "other",
    userId: input.userId ?? null,
  });
  if (bookingResult) {
    const msg =
      bookingResult.action === "created" ||
      bookingResult.action === "reschedule_requested" ||
      bookingResult.action === "cancel_requested"
        ? bookingResult.message
        : bookingResult.action === "ask_clarification" ||
            bookingResult.action === "reschedule_ask" ||
            bookingResult.action === "cancel_confirm_ask"
          ? bookingResult.question
          : null;
    if (msg) {
      return {
        reply: msg,
        success: true,
        totalMs: Date.now() - start,
        correlationId,
      };
    }
    // no_booking ‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏°‡∏µ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏à‡∏≠‡∏á ‚Üí ‡∏´‡πâ‡∏≤‡∏° fall through ‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö "‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞"
    if (bookingResult.action === "no_booking" && isBookingIntent) {
      return {
        reply:
          "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≠‡∏á‡∏ô‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ: ‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•, ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£, ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£/‡∏´‡∏±‡∏ï‡∏ñ‡∏Å‡∏≤‡∏£, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏£‡∏ö‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ô‡∏∞‡∏Ñ‡∏∞ üòä",
        success: true,
        totalMs: Date.now() - start,
        correlationId,
      };
    }
  }

  // Enterprise: Queue / concurrency limit ‚Äî ‡∏£‡∏≠ slot ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
  const releaseSlot = await acquireLLMSlot(input.org_id);

  const ctx: AnalyticsContext = {
    org_id: input.org_id,
    branch_id: input.branch_id ?? null,
    userId: input.userId ?? null,
    correlationId,
    userMessage: trimmed,
  };

  try {
    // Customer Memory ‚Äî ‡πÇ‡∏´‡∏•‡∏î long-term (org-isolated)
    const memory = input.userId
      ? await getCustomerMemory(input.org_id, input.userId)
      : null;

    // Step 1: Run 6 Analytics (parallel, no LLM)
    const analyticsContext = await runAllAnalytics(ctx);

    // Cross-Agent Reasoning
    const crossInsights = runCrossAgentReasoning(analyticsContext);
    const enrichedContext = {
      ...analyticsContext,
      _crossAgentInsights: crossInsights,
      _customerMemory: memory?.summary,
    };

    // Step 2: Role Manager (1 LLM call)
    const customerName = analyticsContext.customer.keyFindings
      .find((f) => f.startsWith("current_customer:"))
      ?.replace("current_customer:", "");

    const rmResult = await runRoleManager({
      userMessage: trimmed,
      analyticsContext: enrichedContext,
      customerName: customerName ?? null,
      correlationId: input.correlationId,
      org_id: input.org_id,
      customerMemorySummary: memory?.summary,
      knowledgeCategory: enrichedContext._knowledgeCategory ?? null,
      channel: input.channel ?? null,
    });

    const totalMs = Date.now() - start;

    // ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï customer memory (increment count)
    if (input.userId) {
      upsertCustomerMemory(input.org_id, input.userId, {
        increment_message_count: true,
      }).catch(() => {});

      // Memory Summarization Job ‚Äî ‡∏ó‡∏∏‡∏Å X ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
      const mem = await getCustomerMemory(input.org_id, input.userId);
      if (mem && shouldSummarize(mem)) {
        void runMemorySummarizationForCustomer(input.org_id, input.userId);
      }
    }

    // üö® DO NOT EXPOSE FINANCE DATA TO CUSTOMER CHAT
    // (1) Zero-leak: Role Manager strip internal (finance) ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ LLM ‡πÄ‡∏°‡∏∑‡πà‡∏≠ channel = line/web
    // (2) Explicit guard: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô customer + ‡∏°‡∏µ INTERNAL_FINANCE_ONLY ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ strip (‡πÄ‡∏ä‡πà‡∏ô channel ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á) ‚Üí block ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÑ‡∏°‡πà‡∏£‡∏≠ policyViolation
    const policyViolation = checkPolicyViolation(rmResult.reply);
    const hallucination = checkHallucination(rmResult.reply);
    const isCustomerChannel = input.channel === "line" || input.channel === "web";
    const hasInternalFinance =
      (analyticsContext.finance as { dataClassification?: string })?.dataClassification === "INTERNAL_FINANCE_ONLY";
    const blockDueToFinanceClassification =
      isCustomerChannel && hasInternalFinance && !rmResult.internalStrippedForCustomer;
    if (policyViolation || hallucination) {
      void tagFailure({
        org_id: input.org_id,
        correlation_id: correlationId,
        failure_type: policyViolation ? "policy_violation" : "hallucination",
        reply: rmResult.reply,
        user_message: trimmed,
      });
    }
    const replyToCustomer =
      blockDueToFinanceClassification || policyViolation || hallucination
        ? "‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡πà‡∏∞ ‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞"
        : rmResult.reply;

    // Enterprise: Cache high-confidence responses
    const analyticsRich =
      analyticsContext.booking.keyFindings.length >= 2 ||
      analyticsContext.promotion.keyFindings.length >= 1 ||
      analyticsContext.knowledge.keyFindings.length >= 1;
    const confidence = computeReplyConfidence(analyticsRich, policyViolation);
    if (confidence >= 0.85 && rmResult.success && !policyViolation && !hallucination) {
      void setCachedResponse({
        org_id: input.org_id,
        userMessage: trimmed,
        reply: rmResult.reply,
        confidence,
        correlationId,
      });
    }

    // Phase 3 #15: Target total orchestration <800ms (retrieval <150ms in knowledge-agent)
    const performanceBreach = totalMs > 800;
    void logAIActivity({
      org_id: input.org_id,
      correlation_id: correlationId,
      prompt_version: rmResult.prompt_version,
      prompt_variant: rmResult.prompt_variant,
      model_version: "gpt-4o-mini",
      tokens_used: rmResult.usage
        ? {
            prompt: rmResult.usage.prompt_tokens,
            completion: rmResult.usage.completion_tokens,
            total: rmResult.usage.total_tokens,
          }
        : undefined,
      agents_triggered: ["booking", "promotion", "customer", "finance", "knowledge", "feedback", "role-manager"],
      total_latency_ms: totalMs,
      latency_per_agent_ms: {
        analytics: analyticsContext.totalAnalyticsMs,
        role_manager: rmResult.totalMs,
      },
      policy_violation_detected: policyViolation,
      hallucination_detected: hallucination,
      retrieval_confidence: analyticsContext._retrievalConfidence,
      retrieval_mode: analyticsContext._retrievalMode,
      knowledge_source: analyticsContext._knowledgeSource,
      knowledge_version: analyticsContext._knowledgeVersion,
      knowledge_version_used: analyticsContext._knowledgeVersion,
      similarity_score: analyticsContext._retrievalConfidence,
      quality_score: analyticsContext._knowledgeQualityScore,
      hallucination_flag: hallucination,
      response_confidence: confidence,
      confidence_level: confidence,
      retrieval_knowledge_ids: analyticsContext._retrievalKnowledgeIds,
      performance_breach: performanceBreach,
    });

    if (input.org_id && rmResult.usage) {
      const { recordLLMUsage } = await import("@/lib/llm-metrics");
      void recordLLMUsage(input.org_id, rmResult.usage, { workloadType: "customer_chat" }).catch((e) =>
        console.error("[orchestrator] recordLLMUsage:", e)
      );
    }

    return {
      reply: replyToCustomer,
      success: rmResult.success,
      analyticsMs: analyticsContext.totalAnalyticsMs,
      roleManagerMs: rmResult.totalMs,
      totalMs,
      error: rmResult.error,
      usage: rmResult.usage,
      correlationId,
      media: rmResult.media,
    };
  } catch (err) {
    const msg = (err as Error)?.message ?? "Unknown error";
    if (isFailsafeError(err)) {
      return {
        reply: FAILSAFE_MESSAGE,
        success: true,
        totalMs: Date.now() - start,
        correlationId,
      };
    }
    return {
      reply: "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Ñ‡πà‡∏∞ ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞",
      success: false,
      totalMs: Date.now() - start,
      error: msg.slice(0, 100),
    };
  } finally {
    releaseSlot();
  }
}
